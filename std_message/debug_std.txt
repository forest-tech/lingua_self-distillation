/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
Tensor parallelism has not been tested for a while, use at your own risk
0: WARNING 25-10-12 17:31:10.716152 - 0:00:00 - Signal handler installed.
0: WARNING 25-10-12 17:31:10.716152 - 0:00:00 - Signal handler installed.
0: WARNING 25-10-12 17:31:10.716769 - 0:00:00 - WARNING: Setting MKL_SERVICE_FORCE_INTEL to GNU
0: WARNING 25-10-12 17:31:10.716769 - 0:00:00 - WARNING: Setting MKL_SERVICE_FORCE_INTEL to GNU
0: WARNING 25-10-12 17:31:10.716867 - 0:00:00 - WARNING: Setting OMP_NUM_THREADS to 1
0: WARNING 25-10-12 17:31:10.716867 - 0:00:00 - WARNING: Setting OMP_NUM_THREADS to 1
0: WARNING 25-10-12 17:31:10.716961 - 0:00:00 - WARNING: Setting MKL_NUM_THREADS to 1
0: WARNING 25-10-12 17:31:10.716961 - 0:00:00 - WARNING: Setting MKL_NUM_THREADS to 1
0: WARNING 25-10-12 17:31:10.717023 - 0:00:00 - WARNING: Setting ENABLE_INTRA_NODE_COMM to 1
0: WARNING 25-10-12 17:31:10.717023 - 0:00:00 - WARNING: Setting ENABLE_INTRA_NODE_COMM to 1
0: WARNING 25-10-12 17:31:10.717081 - 0:00:00 - WARNING: Setting TORCH_NCCL_AVOID_RECORD_STREAMS to 1
0: WARNING 25-10-12 17:31:10.717081 - 0:00:00 - WARNING: Setting TORCH_NCCL_AVOID_RECORD_STREAMS to 1
0: WARNING 25-10-12 17:31:10.717137 - 0:00:00 - WARNING: Setting NCCL_IB_TIMEOUT to 22
0: WARNING 25-10-12 17:31:10.717137 - 0:00:00 - WARNING: Setting NCCL_IB_TIMEOUT to 22
0: WARNING 25-10-12 17:31:10.717187 - 0:00:00 - WARNING: Setting NCCL_DEBUG to INFO
0: WARNING 25-10-12 17:31:10.717187 - 0:00:00 - WARNING: Setting NCCL_DEBUG to INFO
0: WARNING 25-10-12 17:31:10.717241 - 0:00:00 - WARNING: Setting TORCH_NCCL_ASYNC_ERROR_HANDLING to 1
0: WARNING 25-10-12 17:31:10.717241 - 0:00:00 - WARNING: Setting TORCH_NCCL_ASYNC_ERROR_HANDLING to 1
0: WARNING 25-10-12 17:31:10.717291 - 0:00:00 - WARNING: Setting TRITON_CACHE_DIR to /tmp/3815441_ZGVidWcuc2gK/tmpz6c6yq_9
0: WARNING 25-10-12 17:31:10.717291 - 0:00:00 - WARNING: Setting TRITON_CACHE_DIR to /tmp/3815441_ZGVidWcuc2gK/tmpz6c6yq_9
/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
0: INFO    25-10-12 17:31:17.568731 - 0:00:07 - Single GPU job
0: INFO    25-10-12 17:31:17.569052 - 0:00:07 - ENV: environ({'BASH_FUNC_ml%%': '() {  module ml "$@"\n}', 'BASH_FUNC_module%%': '() {  unset _mlshdbg;\n if [ "${MODULES_SILENT_SHELL_DEBUG:-0}" = \'1\' ]; then\n case "$-" in \n *v*x*)\n set +vx;\n _mlshdbg=\'vx\'\n ;;\n *v*)\n set +v;\n _mlshdbg=\'v\'\n ;;\n *x*)\n set +x;\n _mlshdbg=\'x\'\n ;;\n *)\n _mlshdbg=\'\'\n ;;\n esac;\n fi;\n unset _mlre _mlIFS;\n if [ -n "${IFS+x}" ]; then\n _mlIFS=$IFS;\n fi;\n IFS=\' \';\n for _mlv in ${MODULES_RUN_QUARANTINE:-};\n do\n if [ "${_mlv}" = "${_mlv##*[!A-Za-z0-9_]}" -a "${_mlv}" = "${_mlv#[0-9]}" ]; then\n if [ -n "`eval \'echo ${\'$_mlv\'+x}\'`" ]; then\n _mlre="${_mlre:-}${_mlv}_modquar=\'`eval \'echo ${\'$_mlv\'}\'`\' ";\n fi;\n _mlrv="MODULES_RUNENV_${_mlv}";\n _mlre="${_mlre:-}${_mlv}=\'`eval \'echo ${\'$_mlrv\':-}\'`\' ";\n fi;\n done;\n if [ -n "${_mlre:-}" ]; then\n eval `eval ${_mlre} /usr/bin/tclsh /usr/share/Modules/libexec/modulecmd.tcl bash \'"$@"\'`;\n else\n eval `/usr/bin/tclsh /usr/share/Modules/libexec/modulecmd.tcl bash "$@"`;\n fi;\n _mlstatus=$?;\n if [ -n "${_mlIFS+x}" ]; then\n IFS=$_mlIFS;\n else\n unset IFS;\n fi;\n unset _mlre _mlv _mlrv _mlIFS;\n if [ -n "${_mlshdbg:-}" ]; then\n set -$_mlshdbg;\n fi;\n unset _mlshdbg;\n return $_mlstatus\n}', 'BASH_FUNC_scl%%': '() {  if [ "$1" = "load" -o "$1" = "unload" ]; then\n eval "module $@";\n else\n /usr/bin/scl "$@";\n fi\n}', 'BASH_FUNC_switchml%%': '() {  typeset swfound=1;\n if [ "${MODULES_USE_COMPAT_VERSION:-0}" = \'1\' ]; then\n typeset swname=\'main\';\n if [ -e /usr/share/Modules/libexec/modulecmd.tcl ]; then\n typeset swfound=0;\n unset MODULES_USE_COMPAT_VERSION;\n fi;\n else\n typeset swname=\'compatibility\';\n if [ -e /usr/share/Modules/libexec/modulecmd-compat ]; then\n typeset swfound=0;\n MODULES_USE_COMPAT_VERSION=1;\n export MODULES_USE_COMPAT_VERSION;\n fi;\n fi;\n if [ $swfound -eq 0 ]; then\n echo "Switching to Modules $swname version";\n source /usr/share/Modules/init/bash;\n else\n echo "Cannot switch to Modules $swname version, command not found";\n return 1;\n fi\n}', 'BASH_FUNC_which%%': '() {  ( alias;\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@\n}', 'CPATH': '/home/app/cuda/12.2.2/include', 'CPATH_modshare': '/home/app/cuda/12.2.2/include:1', 'CUDA_DIR': '/home/app/cuda/12.2.2', 'CUDA_HOME': '/home/app/cuda/12.2.2', 'CUDA_INSTALL_PATH': '/home/app/cuda/12.2.2', 'CUDA_MPS_LOG_DIRECTORY': '/tmp/nvidia-mps_3815441', 'CUDA_MPS_PIPE_DIRECTORY': '/tmp/nvidia-mps_3815441', 'CUDA_PATH': '/home/app/cuda/12.2.2', 'CUDA_TOP': '/home/app/cuda/12.2.2', 'CYCLECLOUD_BOOTSTRAP': '/opt/cycle/jetpack/system/bootstrap', 'CYCLECLOUD_HOME': '/opt/cycle/jetpack', 'C_INCLUDE_PATH': '/home/app/cuda/12.2.2/include', 'C_INCLUDE_PATH_modshare': '/home/app/cuda/12.2.2/include:1', 'FJPNCKPT_CONFIG': '0x00', 'GENKAI_CACHE_DIR': '/home/cache/pj24001974/ku50001532', 'GENKAI_CUDA_NAME': 'cuda', 'GENKAI_CUDA_VER': '12.2.2', 'GENKAI_FAST_DIR': '/fast/pj24001974', 'HISTCONTROL': 'ignoredups', 'HISTSIZE': '1000', 'HOME': '/home/pj24001974/ku50001532', 'HOSTNAME': 'b0030', 'JOBID': '3815441', 'LANG': 'ja_JP.UTF-8', 'LD_LIBRARY_PATH': '/home/app/cuda/12.2.2/extras/CUPTI/lib64:/home/app/cuda/12.2.2/lib64', 'LD_LIBRARY_PATH_modshare': '/home/app/cuda/12.2.2/extras/CUPTI/lib64:1:/home/app/cuda/12.2.2/lib64:1', 'LESSOPEN': '||/usr/bin/lesspipe.sh %s', 'LIBRARY_PATH': '/home/app/cuda/12.2.2/extras/CUPTI/lib64:/home/app/cuda/12.2.2/lib64', 'LIBRARY_PATH_modshare': '/home/app/cuda/12.2.2/extras/CUPTI/lib64:1:/home/app/cuda/12.2.2/lib64:1', 'LOADEDMODULES': 'cuda/12.2.2', 'LOADEDMODULES_modshare': 'cuda/12.2.2:1', 'LOGNAME': 'ku50001532', 'LUSTRE_JOBSTAT': 'ku50001532@3815441', 'MAIL': '/var/spool/mail/ku50001532', 'MANPATH': ':', 'MIG_PARTED_CHECKPOINT_FILE': '/var/lib/nvidia-mig-manager/checkpoint.json', 'MIG_PARTED_CONFIG_FILE': '/etc/nvidia-mig-manager/config.yaml', 'MIG_PARTED_HOOKS_FILE': '/etc/nvidia-mig-manager/hooks.yaml', 'MODULEPATH': '/home/modules/modulefiles/CNB/compiler/cuda/12.2.2:/home/modules/modulefiles/CNB/core:/home/modules/modulefiles/CNB/util:/home/center/modulefiles:/home/rist/modulefiles', 'MODULEPATH_modshare': '/home/center/modulefiles:1:/home/rist/modulefiles:1:/home/modules/modulefiles/CNB/compiler/cuda/12.2.2:1:/home/modules/modulefiles/CNB/core:1:/home/modules/modulefiles/CNB/util:1', 'MODULESHOME': '/usr/share/Modules', 'MODULES_CMD': '/usr/share/Modules/libexec/modulecmd.tcl', 'MODULES_LMALTNAME': 'cuda/12.2.2&cuda/default&cuda', 'MODULES_LMALTNAME_modshare': 'cuda/12.2.2&cuda/default&cuda:1', 'MODULES_LMCONFLICT': 'cuda/12.2.2&cuda', 'MODULES_LMCONFLICT_modshare': 'cuda/12.2.2&cuda:1', 'MODULES_RUN_QUARANTINE': 'LD_LIBRARY_PATH LD_PRELOAD', 'MOD_GIT_ROOTDIR': '/home/modules', 'OMPI_CKPTCONFIG': '0x00', 'PATH': '/home/pj24001974/ku50001532/lingua/.venv/bin:/home/app/cuda/12.2.2/nsight-systems-2023.2.3:/home/app/cuda/12.2.2/nsight-compute-2023.2.2:/home/app/cuda/12.2.2/bin:/home/pj24001974/ku50001532/.local/bin:/home/pj24001974/ku50001532/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/cycle/jetpack/bin', 'PATH_modshare': '/home/app/cuda/12.2.2/nsight-systems-2023.2.3:1:/home/app/cuda/12.2.2/nsight-compute-2023.2.2:1:/usr/sbin:1:/usr/bin:1:/home/app/cuda/12.2.2/bin:1:/usr/local/sbin:1:/opt/cycle/jetpack/bin:1:/home/pj24001974/ku50001532/.local/bin:1:/home/pj24001974/ku50001532/bin:1:/usr/share/Modules/bin:1:/usr/local/bin:1', 'PJM_ASSIGN_LOGICAL_CPU': 'job', 'PJM_CORE_MEM_LIMIT': '0', 'PJM_CUSTOM_RESOURCES': 'rsc011=0,rsc012=0,rsc013=0,rsc014=0,rsc015=0,rsc016=0,rsc017=0,rsc018=0,rsc019=0,rsc020=0,rsc021=0,rsc022=0,rsc023=0,rsc024=0,rsc025=0,rsc026=0,rsc027=0,rsc028=0,rsc029=0,rsc030=0,rsc031=0,rsc032=0,rsc033=0,rsc034=0,rsc035=0,rsc036=0,rsc037=0,rsc038=0,rsc039=0,rsc040=0,rsc041=0,rsc042=0,rsc043=0,rsc044=0,rsc045=0,rsc046=0,rsc047=0,rsc048=0,rsc049=0,rsc050=0,gpu/n=1,rsc001/n=0,rsc002/n=0,rsc003/n=0,rsc004/n=0,rsc005/n=0,rsc006/n=0,rsc007/n=0,rsc008/n=0,rsc009/n=0,rsc010/n=0,shared/n=true,short-job/n=false', 'PJM_DPREFIX': '#PJM', 'PJM_ELAPSED_TIME_MODE': 'fixed', 'PJM_ELAPSE_LIMIT': '36000', 'PJM_ENVIRONMENT': 'BATCH', 'PJM_EXEC_POLICY': 'share', 'PJM_JOBDIR': '/home/pj24001974/ku50001532/lingua', 'PJM_JOBID': '3815441', 'PJM_JOBNAME': 'debug.sh', 'PJM_MAILOPTION': '0x0', 'PJM_MPI_PROC': '1', 'PJM_NET_ROUTE': 'static', 'PJM_NODE_CPUTIME_LIMIT': '18446744073709551615', 'PJM_O_HOME': '/home/pj24001974/ku50001532', 'PJM_O_HOST': 'genkai0001', 'PJM_O_LANG': 'en_US.UTF-8', 'PJM_O_LOGNAME': 'ku50001532', 'PJM_O_MAIL': '/var/spool/mail/ku50001532', 'PJM_O_NODEINF': '/home/pj24001974/ku50001532/lingua/.d0003815441_nodeinfo', 'PJM_O_PATH': '/home/pj24001974/ku50001532/.local/bin:/home/pj24001974/ku50001532/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/cycle/jetpack/bin:/opt/cycle/jetpack/bin', 'PJM_O_SHELL': '/bin/bash', 'PJM_O_WORKDIR': '/home/pj24001974/ku50001532/lingua', 'PJM_PROC_BY_NODE': '1', 'PJM_RSCGRP': 'b-batch-mig', 'PJM_RSCUNIT': 'rscunit_pg01', 'PJM_SHELL': '/bin/bash', 'PJM_SSD_DIR': '/ssd/3815441', 'PJM_STDERR_PATH': '/home/pj24001974/ku50001532/lingua/debug_std.txt', 'PJM_STDOUT_PATH': '/home/pj24001974/ku50001532/lingua/debug_std.txt', 'PJM_SUBJOBID': '3815441', 'PJM_VNODE': '1', 'PJM_VNODE_CORE': '4', 'PJM_VNODE_MEM_LIMIT': '34760294400', 'PJM_VN_POLICY': 'abs-unpack', 'PLE_SCRIPT_TYPE': 'JOB_SCRIPT', 'PWD': '/home/pj24001974/ku50001532/lingua', 'SHLVL': '2', 'SSH_ASKPASS': '/usr/libexec/openssh/gnome-ssh-askpass', 'S_COLORS': 'auto', 'TMP': '/tmp/3815441_ZGVidWcuc2gK', 'TMPDIR': '/tmp/3815441_ZGVidWcuc2gK', 'TMUX_TMPDIR': '/tmp/3815441_ZGVidWcuc2gK', 'USER': 'ku50001532', 'UV': '/home/pj24001974/ku50001532/.local/bin/uv', 'UV_RUN_RECURSION_DEPTH': '1', 'VIRTUAL_ENV': '/home/pj24001974/ku50001532/lingua/.venv', 'XDG_DATA_DIRS': '/home/pj24001974/ku50001532/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share', '_': '/home/pj24001974/ku50001532/.local/bin/uv', '_LMFILES_': '/home/modules/modulefiles/CNB/core/cuda/12.2.2', '_LMFILES__modshare': '/home/modules/modulefiles/CNB/core/cuda/12.2.2:1', 'which_declare': 'declare -f', 'CUDA_MODULE_LOADING': 'LAZY', 'TORCHINDUCTOR_CACHE_DIR': '/tmp/3815441_ZGVidWcuc2gK/torchinductor_ku50001532', 'MKL_SERVICE_FORCE_INTEL': 'GNU', 'OMP_NUM_THREADS': '1', 'MKL_NUM_THREADS': '1', 'ENABLE_INTRA_NODE_COMM': '1', 'TORCH_NCCL_AVOID_RECORD_STREAMS': '1', 'NCCL_IB_TIMEOUT': '22', 'NCCL_DEBUG': 'INFO', 'TORCH_NCCL_ASYNC_ERROR_HANDLING': '1', 'TRITON_CACHE_DIR': '/tmp/3815441_ZGVidWcuc2gK/tmpz6c6yq_9', 'RANK': '0', 'WORLD_SIZE': '1', 'MASTER_ADDR': '127.0.0.1', 'MASTER_PORT': '28805'})
[W1012 17:31:18.388916340 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [localhost]:28805 (errno: 97 - Address family not supported by protocol).
[W1012 17:31:18.482906116 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
0: INFO    25-10-12 17:31:18.505376 - 0:00:08 - Starting job: debug_20251012
0: INFO    25-10-12 17:31:18.505609 - 0:00:08 - Running on dp rank : 0
0: INFO    25-10-12 17:31:18.505659 - 0:00:08 - Running on dp size : 1
0: INFO    25-10-12 17:31:18.508423 - 0:00:08 - Building model
0: INFO    25-10-12 17:31:18.929547 - 0:00:08 - Model is built !
0: INFO    25-10-12 17:31:23.743488 - 0:00:13 - Model size: 103,306,240 total parameters
0: INFO    25-10-12 17:31:23.744194 - 0:00:13 - GPU capacity: NVIDIA H100 MIG 1g.12gb (0) with 10.75GiB memory
0: INFO    25-10-12 17:31:23.746430 - 0:00:13 - GPU memory usage: NVIDIA H100 MIG 1g.12gb (0): 10.75 GiB capacity, 0.435546875 GiB peak, 4.051598837209302% peak
0: INFO    25-10-12 17:31:23.746562 - 0:00:13 - Starting build of optimizer...
0: INFO    25-10-12 17:31:23.747103 - 0:00:13 - Done with build of optimizer.
/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
0: INFO    25-10-12 17:31:23.837766 - 0:00:13 - Async dataloader started
0: INFO    25-10-12 17:31:23.838725 - 0:00:13 - Profiling active.  Traces will be saved at outputs/debug_20251012/profiling
/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
0: INFO    25-10-12 17:31:31.098526 - 0:00:20 - garbage collection
0: INFO    25-10-12 17:31:41.722291 - 0:00:31 - Killing async data process 169 ...
0: INFO    25-10-12 17:31:41.722546 - 0:00:31 - Async dataloader cleaned up
b0030:94:94 [0] NCCL INFO Bootstrap: Using ib0:172.17.17.30<0>
b0030:94:94 [0] NCCL INFO cudaDriverVersion 13000
b0030:94:94 [0] NCCL INFO NCCL version 2.27.3+cuda12.9
b0030:94:94 [0] NCCL INFO Comm config Blocking set to 1
b0030:94:163 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. 
b0030:94:163 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:172.17.17.30<0>
b0030:94:163 [0] NCCL INFO Initialized NET plugin IB
b0030:94:163 [0] NCCL INFO Assigned NET plugin IB to comm
b0030:94:163 [0] NCCL INFO Using network IB
b0030:94:163 [0] NCCL INFO DMA-BUF is available on GPU device 0
b0030:94:163 [0] NCCL INFO ncclCommInitRankConfig comm 0x55a07a20df00 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ac000 commId 0x4cef9927899a674 - Init START
b0030:94:163 [0] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
b0030:94:163 [0] NCCL INFO Bootstrap timings total 0.001342 (create 0.000025, send 0.000132, recv 0.000199, ring 0.000003, delay 0.000002)
b0030:94:163 [0] NCCL INFO comm 0x55a07a20df00 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
b0030:94:163 [0] NCCL INFO Channel 00/64 : 0
b0030:94:163 [0] NCCL INFO Channel 01/64 : 0
b0030:94:163 [0] NCCL INFO Channel 02/64 : 0
b0030:94:163 [0] NCCL INFO Channel 03/64 : 0
b0030:94:163 [0] NCCL INFO Channel 04/64 : 0
b0030:94:163 [0] NCCL INFO Channel 05/64 : 0
b0030:94:163 [0] NCCL INFO Channel 06/64 : 0
b0030:94:163 [0] NCCL INFO Channel 07/64 : 0
b0030:94:163 [0] NCCL INFO Channel 08/64 : 0
b0030:94:163 [0] NCCL INFO Channel 09/64 : 0
b0030:94:163 [0] NCCL INFO Channel 10/64 : 0
b0030:94:163 [0] NCCL INFO Channel 11/64 : 0
b0030:94:163 [0] NCCL INFO Channel 12/64 : 0
b0030:94:163 [0] NCCL INFO Channel 13/64 : 0
b0030:94:163 [0] NCCL INFO Channel 14/64 : 0
b0030:94:163 [0] NCCL INFO Channel 15/64 : 0
b0030:94:163 [0] NCCL INFO Channel 16/64 : 0
b0030:94:163 [0] NCCL INFO Channel 17/64 : 0
b0030:94:163 [0] NCCL INFO Channel 18/64 : 0
b0030:94:163 [0] NCCL INFO Channel 19/64 : 0
b0030:94:163 [0] NCCL INFO Channel 20/64 : 0
b0030:94:163 [0] NCCL INFO Channel 21/64 : 0
b0030:94:163 [0] NCCL INFO Channel 22/64 : 0
b0030:94:163 [0] NCCL INFO Channel 23/64 : 0
b0030:94:163 [0] NCCL INFO Channel 24/64 : 0
b0030:94:163 [0] NCCL INFO Channel 25/64 : 0
b0030:94:163 [0] NCCL INFO Channel 26/64 : 0
b0030:94:163 [0] NCCL INFO Channel 27/64 : 0
b0030:94:163 [0] NCCL INFO Channel 28/64 : 0
b0030:94:163 [0] NCCL INFO Channel 29/64 : 0
b0030:94:163 [0] NCCL INFO Channel 30/64 : 0
b0030:94:163 [0] NCCL INFO Channel 31/64 : 0
b0030:94:163 [0] NCCL INFO Channel 32/64 : 0
b0030:94:163 [0] NCCL INFO Channel 33/64 : 0
b0030:94:163 [0] NCCL INFO Channel 34/64 : 0
b0030:94:163 [0] NCCL INFO Channel 35/64 : 0
b0030:94:163 [0] NCCL INFO Channel 36/64 : 0
b0030:94:163 [0] NCCL INFO Channel 37/64 : 0
b0030:94:163 [0] NCCL INFO Channel 38/64 : 0
b0030:94:163 [0] NCCL INFO Channel 39/64 : 0
b0030:94:163 [0] NCCL INFO Channel 40/64 : 0
b0030:94:163 [0] NCCL INFO Channel 41/64 : 0
b0030:94:163 [0] NCCL INFO Channel 42/64 : 0
b0030:94:163 [0] NCCL INFO Channel 43/64 : 0
b0030:94:163 [0] NCCL INFO Channel 44/64 : 0
b0030:94:163 [0] NCCL INFO Channel 45/64 : 0
b0030:94:163 [0] NCCL INFO Channel 46/64 : 0
b0030:94:163 [0] NCCL INFO Channel 47/64 : 0
b0030:94:163 [0] NCCL INFO Channel 48/64 : 0
b0030:94:163 [0] NCCL INFO Channel 49/64 : 0
b0030:94:163 [0] NCCL INFO Channel 50/64 : 0
b0030:94:163 [0] NCCL INFO Channel 51/64 : 0
b0030:94:163 [0] NCCL INFO Channel 52/64 : 0
b0030:94:163 [0] NCCL INFO Channel 53/64 : 0
b0030:94:163 [0] NCCL INFO Channel 54/64 : 0
b0030:94:163 [0] NCCL INFO Channel 55/64 : 0
b0030:94:163 [0] NCCL INFO Channel 56/64 : 0
b0030:94:163 [0] NCCL INFO Channel 57/64 : 0
b0030:94:163 [0] NCCL INFO Channel 58/64 : 0
b0030:94:163 [0] NCCL INFO Channel 59/64 : 0
b0030:94:163 [0] NCCL INFO Channel 60/64 : 0
b0030:94:163 [0] NCCL INFO Channel 61/64 : 0
b0030:94:163 [0] NCCL INFO Channel 62/64 : 0
b0030:94:163 [0] NCCL INFO Channel 63/64 : 0
b0030:94:163 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1 [32] -1/-1/-1->0->-1 [33] -1/-1/-1->0->-1 [34] -1/-1/-1->0->-1 [35] -1/-1/-1->0->-1 [36] -1/-1/-1->0->-1 [37] -1/-1/-1->0->-1 [38] -1/-1/-1->0->-1 [39] -1/-1/-1->0->-1 [40] -1/-1/-1->0->-1 [41] -1/-1/-1->0->-1 [42] -1/-1/-1->0->-1 [43] -1/-1/-1->0->-1 [44] -1/-1/-1->0->-1 [45] -1/-1/-1->0->-1 [46] -1/-1/-1->0->-1 [47] -1/-1/-1
b0030:94:163 [0] NCCL INFO P2P Chunksize set to 524288
b0030:94:163 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
b0030:94:163 [0] NCCL INFO Check P2P Type isAllDirectP2p 0 directMode 0
b0030:94:167 [0] NCCL INFO [Proxy Service] Device 0 CPU core 59
b0030:94:168 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 56
b0030:94:163 [0] NCCL INFO 64 coll channels, 64 collnet channels, 0 nvls channels, 64 p2p channels, 64 p2p channels per peer
b0030:94:163 [0] NCCL INFO CC Off, workFifoBytes 1048576
b0030:94:163 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
b0030:94:163 [0] NCCL INFO ncclCommInitRankConfig comm 0x55a07a20df00 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId ac000 commId 0x4cef9927899a674 - Init COMPLETE
b0030:94:163 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 1 total 1.04 (kernels 0.93, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.02, rest 0.01)
[rank0]: Traceback (most recent call last):
[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:   File "/home/pj24001974/ku50001532/lingua/apps/main/train.py", line 657, in <module>
[rank0]:     main()
[rank0]:   File "/home/pj24001974/ku50001532/lingua/apps/main/train.py", line 653, in main
[rank0]:     train(cfg)
[rank0]:   File "/home/pj24001974/ku50001532/lingua/apps/main/train.py", line 403, in train
[rank0]:     probe_loss = model(
[rank0]:                  ^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/apps/main/transformer.py", line 113, in forward
[rank0]:     h = super().forward(h, tok_idx=tok_idx, mask=mask, attn_impl=attn_impl)
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/transformer.py", line 581, in forward
[rank0]:     h = layer(h, freq_cis, tok_idx=tok_idx, mask=mask, attn_impl=attn_impl)
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/transformer.py", line 542, in forward
[rank0]:     out = h + self.feed_forward(self.ffn_norm(h))
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/transformer.py", line 469, in forward
[rank0]:     x1 = self.w1(x.view_as(x))
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
[rank0]:     return inner()
[rank0]:            ^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/probe.py", line 419, in __torch_dispatch__
[rank0]:     self.log_tensor(f"{path}::out", out)
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/probe.py", line 387, in log_tensor
[rank0]:     self.store[name] = _get_stats(x, **kwargs)
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/pj24001974/ku50001532/lingua/lingua/probe.py", line 103, in _get_stats
[rank0]:     "skew": (((x - mean) / std) ** 3).double().mean(),
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1131, please report a bug to PyTorch. 
